{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9172545",
   "metadata": {},
   "source": [
    "# MultiVectorStore\n",
    "\n",
    "It can often be beneficial to store multiple vectors per document. There are multiple use cases where this is beneficial. LangChain has a base `MultiVectorRetriever` which makes querying this type of setup easy. A lot of the complexity lies in how to create the multiple vectors per document. This notebook covers some of the common ways to create those vectors and use the `MultiVectorRetriever`.\n",
    "\n",
    "The methods to create multiple vectors per document include:\n",
    "\n",
    "- Smaller chunks: split a document into smaller chunks, and embed those (this is ParentDocumentRetriever).\n",
    "- Summary: create a summary for each document, embed that along with (or instead of) the document.\n",
    "- Hypothetical questions: create hypothetical questions that each document would be appropriate to answer, embed those along with (or instead of) the document.\n",
    "\n",
    "\n",
    "Note that this also enables another method of adding embeddings - manually. This is great because you can explicitly add questions or queries that should lead to a document being recovered, giving you more control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d3504ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_folder = os.path.abspath(\"../data/full_stack\")\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from load_document import load_document\n",
    "from cached_docstore import CachedDocStore\n",
    "from multi_vectorstore import MultiVectorStore\n",
    "from document_db import DocumentDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d869496",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = load_document(\"./files/state_of_the_union.txt\", chunk_it=True, chunk_size=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8482dc47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b44d74a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3849"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e7b6b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "base_vectorstore = Chroma(\n",
    "                persist_directory=data_folder+\"/vectors\",\n",
    "                embedding_function=embedding,\n",
    "            )\n",
    "\n",
    "\n",
    "docstore = CachedDocStore(data_folder+\"/parent_docs\", cached=False)\n",
    "\n",
    "multi_vectorstore = MultiVectorStore(\n",
    "                vectorstore=base_vectorstore,\n",
    "                docstore=docstore,\n",
    "                ids_db_path=data_folder,\n",
    "                functor=\"chunk\",\n",
    "                func_kwargs={\"chunk_size\": 400},\n",
    "                search_kwargs={\"k\": 1},\n",
    "        )\n",
    "\n",
    "db = DocumentDB(data_folder, vectorstore=multi_vectorstore)\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4508b7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_added': 0, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 11}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0d06ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_added': 11, 'num_updated': 0, 'num_skipped': 0, 'num_deleted': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.upsert_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b442b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_docs = base_vectorstore.similarity_search(\"justice breyer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5508b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sub_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649108da",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sub_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7594b24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "related_docs = retriever.invoke(\"justice breyer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5975e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(related_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c120c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(related_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac7395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
